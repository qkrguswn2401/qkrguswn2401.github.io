---
title: "Very Deep Convolutional Networks for Text Classification"
date: 2021-03-03 08:26:28 -0400
categories: Paper Review NLP
---
Abstract: NLP분야에서 CNN의 깊이는 CV에서 사용되는 CNN 깊이보다 shallow 했다.  VDCNN은 VGG16 처럼 kernel 사이즈를 작게하고, 깊게 했을시, 
몇 public classifcication dataset에서 sota 성능을 보였다.  Deep CNN 이 text에 처음으로 사용되었다. 

Introduction:
token 은 sequential하기때문에 (Left -> Right) NLP 분야에서는 RNN이 많이 쓰여진다.  sequence는 RNN (LSTM)의 hidden로 기억된다.
LSTM은 sequence를 처리하기위한 generic한 방법이지만, task-specific 하지 않다.  
Text processing에서 ConvNets을 사용한 사례는 있었지만, 이번에 제시된 VDCNN은 이전 ConvNets보다 더 좋은 성능을 보여주고있다.


Related Work:
전반적으로 Text classification은 2stage로 진행된다, feature extraction -> classification.  Feature Extraction은 BOW or n-gram 그리고 이것으로 TF-IDF만들어 사용한다.
다른 방식으로는 RNN을 이용하는 것인데.  마지막 time-step에 나오는 것은 sentence를 represent vector이다. 
CNN이 NLP에 처음으로 사용된건 2014 Kim의 1 conv layer followed by a max pool -> fc with drop-out.   2014 Kalchbrenner이 CNN으로 classification 했는데 다른점은 5 conv layer와 temporal k-max pooling 을 썻다는 것이다.  k-max pooling으로 얻은 이점은 sentence에있는 k feature를 independent하게 추출한다는 것이었다.  이 architecture의 공통점은 다 shallow 하다는거였다.
Computer vision field에서는 VGG혹은 Resnet과 같은 깊은 cnn 구조들이 등장했고, NLP에서는 Deeper layer를 적용하는게 시도지 않았다.  이 논문은 29 Conv layer를 적용하였고, 이 구조는 앞에 나온 구조들보다 더 좋은 성능을 보여주었다.

VDCNN Architecture:
1: The architecture starts with 2D look-up table, namely, nn.embedding. \\
2: 64 Convolution with size of 3 with conv block afterwards.  \\
3: Inspired by VGG or ResNet, two rules are applied, 이렇게 하면 network의 memory usage 가 줄어드는걸 도와준다. (2 must follow rules)\\
  3-1: 같은 temporal resolution output을 갖기위하여, 모든 layers들은 같은 feature맵은 가지고있어야하고. \\
  3-2: temporal resolution이 반토막이 될때, feature map은 두배가 된다.\\
Important: 문장의 길이가 가변적이여서 fixed length (1024)를 padding 통하여 처리한다.\\
4: 3 poolng operations 이 존재하면, pooling을 거칠때 마다 temporal resoultion이 반으로 줄며, feature map은 2배씩 늘어난다.   64->128->256->512\\
5: 이 laye을 거친 high-level representation은 text을 잘 나타낸다.  \\
6: 기존에 shallow convnet들은 kernel size: 3,5,7 이였으며 이와같이 한 이유는 kernel size 만큼 n-gram feature이 짧거나, 토큰이 긴-span relation을 찾아줬었다. 여기서는 더 깊은 convnet으로 kernel size:3으로 했다.  layer들을 블락 단위로 쌓으면 9개의 토큰간의 정보를 추출하여, 9 토큰안에 있는 각각의 토큰은 independent하게 3-gram feature를 깊은 네트워크 구조가 최선의 방법으로 조합할지 학습한다 (VGG 아이디어)  why 3 gram? Empircally shown that 3gram performes the best.\\
7: ResNet shortcut연결 방식을 사용했으며, 이는 1x1 convolution과 같다.  \\
8: Task가 Text classification이니, temporal resolution은 k-max pooling통하여  down-sampled되어 고정된 dimension을 맞췄다. 문장에 postion에 상관없이 가장 중요한 k개의 feature가 추출된다.   \\
9: 512 by k 는 3개의 FC의 인풋이되며, 각 fc는 regularaization 방법인 drop-out을 쓰지않으며, regularization은 conv block안에 conv layer 후 temporal batch normalization으로 처리하였다. \\

K = s^p  where p is number of pooling and s is 1024 (fixed)

Batch Normalization:
It normalizes over mini batch.
In optimization's perspective, steeper and rougher valleys and hills become smoother due to batch normalization or decreases the number of hills and valleys.

Temporal Batch Normalization: 
It normalizes over time steps.
Pros:  becasue we are normalizing over time, it is context-indepedent normalization.  
![image](https://user-images.githubusercontent.com/36841216/109766492-95045000-7c39-11eb-85b6-3671f5f2fd74.png)





![image](https://user-images.githubusercontent.com/36841216/109649190-e9a6bd00-7b9e-11eb-96fb-391d2a05748e.png)
VDCNN 구조
![image](https://user-images.githubusercontent.com/36841216/109649527-646fd800-7b9f-11eb-8cde-49d56da70622.png)
ConvBlock 구조
