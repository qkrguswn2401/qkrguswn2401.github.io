---
title: "Weighted Finite-State Transduce(WFST)"
date: 2021-03-25 08:26:28 -0400
categories: Speech-Recognition
---
Motivation: Simple HMM model with small vocab can be decoded with Viterbi decoding.  When vocabulray is large or input data is big, models become too complex to be solved unlike the HMM with small vocabulary size.  

WFST is compoesed of  multiple transducers to a signle transducer and uses it to search for a grammtically-sound sentence.
It provides a natural representation for HMM phonetic models, context-dependent phones, pronunciation lexicons, and grammars.




Weights are associated with edges as costs or probability.
WFST composes transducers together to build structures.  Transducer encode a mapping between the input and the output label sequences.  
From the table below, HMM trasducers convert HMM states into context-depedent phones. For each part, transducers are combined -> decoder is created.  
<br/> Transducer H (HMM)
<br/>![image](https://user-images.githubusercontent.com/36841216/115950124-5e013b00-a514-11eb-8727-37b6fc2df18b.png)
<br/> top: grammar, middle: pronunciation lexicon, bottom: hmm phone model.
<br/> H converts HMM states into context-dependent (CD) phones.

<br/> transducer L (pronunciation lexicon transducer):
![image](https://user-images.githubusercontent.com/36841216/112437359-3474b880-8d8a-11eb-9720-55540060e566.png)
pronunciation lexicon transducer을 이용해 input phone로 받아 words output을 만들어낸다.  ex) /b/ /ih/ /l/ phone을 받아 bill이라는 word 아웃풋을 뽑아낸다.
![image](https://user-images.githubusercontent.com/36841216/112440531-c631f500-8d8d-11eb-8fda-ff92c0c2d990.png)

Transducer G:
![image](https://user-images.githubusercontent.com/36841216/113383793-a28b3200-93bf-11eb-8f30-f74b3ef7745d.png)
마지막 state에 word마다 likehood를 가지고있으며, 단어의 순서로 연결되야 (condition) 의미, 문법적으로 맞는지 확률로 계산.

<br/> Finite State Automaton (Finite State Machine)
![image](https://user-images.githubusercontent.com/36841216/112444018-efa05000-8d90-11eb-843b-f97f347bbff5.png)
<br/>Input a is received with wiehgt 0.6  (first state)  output: e is passed to next state with the weight.

Semiring: set R is equipped with two binary operations + and '(multiplication) s.t. four conditions exisit.
![image](https://user-images.githubusercontent.com/36841216/113384883-fac33380-93c1-11eb-9a2c-5e60aeb85e60.png)
Semiring 예시:
![image](https://user-images.githubusercontent.com/36841216/113386269-d87ee500-93c4-11eb-9999-cd1df7c67895.png)

![image](https://user-images.githubusercontent.com/36841216/115950024-b5eb7200-a513-11eb-86dd-fddf0d3044f9.png)
<br/>Figure of language model and prononciation lexion
For langauge model, both input and output models are the same, its purpose is to calculate probability for a word sequence.



